{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trish-Pat/DIBootCamp/blob/main/Week9_day_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 1: Calculating Required Sample Size**"
      ],
      "metadata": {
        "id": "Ry5EnhRyivBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnv1yX0UiB6r",
        "outputId": "06b391f3-f17d-4650-c3ac-7b75e52b7cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required sample size: 175.38\n"
          ]
        }
      ],
      "source": [
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "# Parameters\n",
        "effect_size = 0.3\n",
        "alpha = 0.05\n",
        "power = 0.8\n",
        "\n",
        "# Calculate the sample size\n",
        "power_analysis = TTestIndPower()\n",
        "sample_size = power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "\n",
        "print(f\"Required sample size: {sample_size:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2: Understanding the Relationship Between Effect Size and Sample Size**"
      ],
      "metadata": {
        "id": "hL4tXUEevtLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "effect_size = [0.2, 0.4, 0.5]\n",
        "alpha = 0.05\n",
        "power = 0.8\n",
        "\n",
        "for effect in effect_size:\n",
        "    # Calculate the sample size\n",
        "    power_analysis = TTestIndPower()\n",
        "    sample_size = power_analysis.solve_power(effect_size=effect, alpha=alpha, power=power)\n",
        "\n",
        "    print(f\"Required sample size: {sample_size:.2f} for effect_size = {effect}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5CIvz_gr-WU",
        "outputId": "bdfa5d73-9a36-4b76-fe9e-5be1ce61aa05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required sample size: 393.41 for effect_size = 0.2\n",
            "Required sample size: 99.08 for effect_size = 0.4\n",
            "Required sample size: 63.77 for effect_size = 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*As the effect size increases, the sample size decreases. It is because a large effect size is easier to detect with a smaller sample size. The larger the effect size, the easier it is to detect a difference between the two groups.*"
      ],
      "metadata": {
        "id": "xPr-GCpWxwBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Exploring the Impact of Statistical Power**"
      ],
      "metadata": {
        "id": "MYkVgaXkyr2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "effect_size = 0.2\n",
        "alpha = 0.05\n",
        "power = [0.7, 0.8, 0.9]\n",
        "\n",
        "for p in power:\n",
        "    # Calculate the sample size\n",
        "    power_analysis = TTestIndPower()\n",
        "    sample_size = power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=p)\n",
        "\n",
        "    print(f\"Required sample size: {sample_size:.2f} for power = {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9XMB0aMt1YG",
        "outputId": "84ca02e0-cf9e-4e69-fbd3-dac62e78b713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required sample size: 309.56 for power = 0.7\n",
            "Required sample size: 393.41 for power = 0.8\n",
            "Required sample size: 526.33 for power = 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.With a small sample size, your A/B test has low statistical power which might lead to 'false negative'\n",
        "2. A large sample size gives your A/B test high statistical power,which in turn increases the chances that you will detect the  difference between the layouts if one exists.\n",
        "\n",
        "With high statistical power, you can be more confident that the results are reliable and thus allowing you to make data-driven decisions with greater certainty."
      ],
      "metadata": {
        "id": "8yYWBl6kpfJM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76LvmCdvqHmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4: Implementing Sequential Testing**"
      ],
      "metadata": {
        "id": "V3jk0P08q0U0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are running an A/B test on two versions of a product page to increase the purchase rate. You plan to monitor the results weekly and stop the test early if one version shows a significant improvement."
      ],
      "metadata": {
        "id": "FjVdIeLurYYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define your stopping criteria.\n",
        "\n",
        "Will set it at 0.05, meaning there is  a 5% chance of being wrong, if I conclude the version is better. So it means that if one version has a p-value less than 0.05 at any checkpoint, the test should stop."
      ],
      "metadata": {
        "id": "CIg-AzYerbbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Decide how you would implement sequential testing in this scenario.\n",
        "\n",
        "*I set the test run and check the results at regular intervals, for instance, every week. At each interval, I will calculate the p-value to see if there's already a significant difference between the two versions and if I reach the stopping creteria before the end of the test, I stop.*"
      ],
      "metadata": {
        "id": "JKHKFIwLsT-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- At the end of week three, Version B has a p-value of 0.02. What would you do next?\n",
        "\n",
        "*If our stopping criteria is at 0.05 and version B has a p-value of 0.02 < 0.05, then we should stop the test and conclude that version B performs better.*"
      ],
      "metadata": {
        "id": "HYq0osdztIia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5: Applying Bayesian A/B Testing**"
      ],
      "metadata": {
        "id": "KE_gVKumuTXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’re testing a new feature in your app, and you want to use a Bayesian approach. Initially, you believe the new feature has a 50% chance of improving user engagement. After collecting data, your analysis suggests a 65% probability that the new feature is better."
      ],
      "metadata": {
        "id": "Q8avBogPvYb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Describe how you would set up your prior belief.\n",
        "\n",
        "*The new feature has a 50% chance of improving user engagement, so we start with a prior belief that new feature (version B) has 50% chance being better than the current one (version A).*"
      ],
      "metadata": {
        "id": "34BJxYgjvarM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- After collecting data, how does the updated belief (posterior distribution) influence your decision?\n",
        "\n",
        "*After collection data, we see that version B is perfoming better than we expected. We update our belief (posterior), which now shows that version B has a 65% probability of being better than version A.*"
      ],
      "metadata": {
        "id": "AH5zgjuJwNhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What would you do if the posterior probability was only 55%?\n",
        "\n",
        "*We would update our belief (posterior), which shows that version B has a 55% probability of being better than version A.\n",
        "But 55% posterior probability indicates very weak evidence that version B is better than version A. It’s only slightly better than random chance, so we would continue collecting data rather than deploying the new feature. We would wait for the posterior to increase to a more confident threshold before deciding.*\n"
      ],
      "metadata": {
        "id": "AbQ07EfByLji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 6: Implementing Adaptive Experimentation**"
      ],
      "metadata": {
        "id": "cjltReEz1THt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’re running a test with three different website layouts to increase user engagement. Initially, each layout gets 33% of the traffic. After the first week, Layout C shows higher engagement."
      ],
      "metadata": {
        "id": "SdTrFsm_1YyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Explain how you would adjust the traffic allocation after the first week.\n",
        "\n",
        "Since Layout C shows higher engagement, we would start sending more visitors to it and reduce traffic to layouts A and B. For example, we might allocate 50% of the traffic to C and 25% to each of the other two layouts."
      ],
      "metadata": {
        "id": "vvsjBDNv1ap2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Describe how you would continue to adapt the experiment in the following weeks.\n",
        "\n",
        "*By continuing to  adjust traffic based on the lastest data. If a certain  layout starts performing better than the rest, then we will shift more traffic to it while reducing traffic to the lower-performing versions."
      ],
      "metadata": {
        "id": "4w107V3e22Vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What challenges might you face with adaptive experimentation, and how would you address them?\n",
        "\n",
        "*Challenge with adaptive experimentation is the\n",
        "risk of prematurely favoring a layout that appears better due to random variation. To solve this  algorithms that balance exploration and exploitation can be used to  gradually increase traffic fr better-performing layouts."
      ],
      "metadata": {
        "id": "OAyBxMwB3Pg6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPnLgW6toZdY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}